#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
ç”¨äºæ‰¹é‡æµ‹è¯•PDFæ–‡ä»¶çš„OCRè¯†åˆ«å’Œå·¥ä½œæµåˆ†æ
"""

import os
import glob
import json
import time
import requests
import shutil
from datetime import datetime
from pathlib import Path
import argparse
import sys

class AutoTestRunner:
    """è‡ªåŠ¨åŒ–æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, base_url="http://localhost:5000", output_dir="test_results"):
        """
        åˆå§‹åŒ–æµ‹è¯•è¿è¡Œå™¨
        
        Args:
            base_url (str): Webåº”ç”¨çš„åŸºç¡€URL
            output_dir (str): æµ‹è¯•ç»“æœè¾“å‡ºç›®å½•
        """
        self.base_url = base_url
        self.output_dir = output_dir
        self.session = requests.Session()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.test_results = {
            "test_info": {
                "start_time": datetime.now().isoformat(),
                "base_url": base_url,
                "output_dir": output_dir
            },
            "pdf_files": [],
            "ocr_results": {},
            "analysis_results": {},
            "errors": [],
            "summary": {}
        }
    
    def find_pdf_files(self, pdf_path):
        """
        æŸ¥æ‰¾æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰PDFæ–‡ä»¶
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶å¤¹æˆ–å•ä¸ªæ–‡ä»¶
            
        Returns:
            list: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        pdf_files = []
        
        if os.path.isfile(pdf_path):
            if pdf_path.lower().endswith('.pdf'):
                pdf_files.append(pdf_path)
        elif os.path.isdir(pdf_path):
            # é€’å½’æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
            pattern = os.path.join(pdf_path, "**", "*.pdf")
            pdf_files = glob.glob(pattern, recursive=True)
        
        print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        for pdf_file in pdf_files:
            print(f"  - {pdf_file}")
        
        return pdf_files
    
    def check_server_status(self):
        """æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€"""
        try:
            response = self.session.get(f"{self.base_url}/")
            if response.status_code == 200:
                print("âœ… æœåŠ¡å™¨è¿æ¥æ­£å¸¸")
                return True
            else:
                print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
            return False
    
    def upload_pdf_files(self, pdf_files):
        """
        ä¸Šä¼ PDFæ–‡ä»¶åˆ°æœåŠ¡å™¨ï¼ˆæ”¯æŒåˆ†æ‰¹ä¸Šä¼ ï¼‰
        
        Args:
            pdf_files (list): PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            str: ä»»åŠ¡IDï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶å†³å®šæ˜¯å¦åˆ†æ‰¹ä¸Šä¼ 
        total_size = sum(os.path.getsize(f) for f in pdf_files)
        max_size = 80 * 1024 * 1024  # 80MBï¼Œç•™ä¸€äº›ä½™é‡
        
        print(f"ğŸ“Š æ–‡ä»¶æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")
        
        if total_size > max_size:
            print(f"âš ï¸  æ–‡ä»¶æ€»å¤§å°è¶…è¿‡é™åˆ¶ï¼Œå°†è¿›è¡Œåˆ†æ‰¹ä¸Šä¼ ...")
            return self._upload_files_in_batches(pdf_files, max_size)
        else:
            return self._upload_files_single_batch(pdf_files)
    
    def _upload_files_single_batch(self, pdf_files):
        """å•æ‰¹ä¸Šä¼ æ–‡ä»¶"""
        try:
            files = []
            for pdf_file in pdf_files:
                files.append(('files', (os.path.basename(pdf_file), open(pdf_file, 'rb'), 'application/pdf')))
            
            print(f"ğŸ“¤ å¼€å§‹ä¸Šä¼  {len(pdf_files)} ä¸ªPDFæ–‡ä»¶...")
            response = self.session.post(f"{self.base_url}/upload", files=files)
            
            # å…³é—­æ–‡ä»¶å¥æŸ„
            for _, (_, file_obj, _) in files:
                file_obj.close()
            
            if response.status_code == 200:
                result = response.json()
                task_id = result.get('task_id')
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}")
                
                # è®°å½•ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯
                self.test_results["pdf_files"] = [os.path.basename(f) for f in pdf_files]
                self.test_results["task_id"] = task_id
                
                return task_id
            else:
                error_msg = f"ä¸Šä¼ å¤±è´¥: {response.status_code} - {response.text}"
                print(f"âŒ {error_msg}")
                self.test_results["errors"].append(error_msg)
                return None
                
        except Exception as e:
            error_msg = f"ä¸Šä¼ å¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            self.test_results["errors"].append(error_msg)
            return None
    
    def _upload_files_in_batches(self, pdf_files, max_batch_size):
        """åˆ†æ‰¹ä¸Šä¼ æ–‡ä»¶"""
        # æŒ‰æ–‡ä»¶å¤§å°åˆ†ç»„
        batches = []
        current_batch = []
        current_size = 0
        
        for pdf_file in pdf_files:
            file_size = os.path.getsize(pdf_file)
            
            # å¦‚æœå•ä¸ªæ–‡ä»¶å°±è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡
            if file_size > max_batch_size:
                print(f"âš ï¸  æ–‡ä»¶ {os.path.basename(pdf_file)} å¤ªå¤§({file_size/1024/1024:.2f}MB)ï¼Œè·³è¿‡")
                continue
            
            # å¦‚æœæ·»åŠ è¿™ä¸ªæ–‡ä»¶ä¼šè¶…è¿‡æ‰¹æ¬¡é™åˆ¶ï¼Œå¼€å§‹æ–°æ‰¹æ¬¡
            if current_size + file_size > max_batch_size and current_batch:
                batches.append(current_batch)
                current_batch = []
                current_size = 0
            
            current_batch.append(pdf_file)
            current_size += file_size
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch:
            batches.append(current_batch)
        
        print(f"ğŸ“¦ å°†åˆ† {len(batches)} æ‰¹ä¸Šä¼ ")
        
        # é€æ‰¹ä¸Šä¼ 
        all_task_ids = []
        for i, batch in enumerate(batches, 1):
            print(f"\nğŸ”„ ç¬¬ {i}/{len(batches)} æ‰¹ - {len(batch)} ä¸ªæ–‡ä»¶")
            task_id = self._upload_files_single_batch(batch)
            if task_id:
                all_task_ids.append(task_id)
                # ç­‰å¾…è¿™æ‰¹å¤„ç†å®Œæˆå†ä¸Šä¼ ä¸‹ä¸€æ‰¹
                if i < len(batches):
                    print("â³ ç­‰å¾…å½“å‰æ‰¹æ¬¡å¤„ç†å®Œæˆ...")
                    ocr_results = self.wait_for_ocr_completion(task_id)
                    if not ocr_results:
                        print(f"âŒ ç¬¬ {i} æ‰¹å¤„ç†å¤±è´¥")
                        return None
            else:
                print(f"âŒ ç¬¬ {i} æ‰¹ä¸Šä¼ å¤±è´¥")
                return None
        
        # è¿”å›æœ€åä¸€ä¸ªtask_idï¼ˆç”¨äºæœ€ç»ˆåˆ†æï¼‰
        return all_task_ids[-1] if all_task_ids else None
    
    def wait_for_ocr_completion(self, task_id, timeout=3600):
        """
        ç­‰å¾…OCRå¤„ç†å®Œæˆ
        
        Args:
            task_id (str): ä»»åŠ¡ID
            timeout (int): è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            dict: OCRç»“æœï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        print("â³ ç­‰å¾…OCRå¤„ç†å®Œæˆ...")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                response = self.session.get(f"{self.base_url}/status/{task_id}")
                
                if response.status_code == 200:
                    status = response.json()
                    
                    if status.get('status') == 'processing':
                        progress = status.get('progress', 0)
                        total = status.get('total', 0)
                        print(f"ğŸ“‹ å¤„ç†è¿›åº¦: {progress}/{total}")
                        
                    elif status.get('status') == 'completed':
                        print("âœ… OCRå¤„ç†å®Œæˆ")
                        ocr_results = status.get('results', [])
                        self.test_results["ocr_results"] = ocr_results
                        return ocr_results
                        
                    elif status.get('status') == 'error':
                        error_msg = f"OCRå¤„ç†å¤±è´¥: {status.get('error', 'æœªçŸ¥é”™è¯¯')}"
                        print(f"âŒ {error_msg}")
                        self.test_results["errors"].append(error_msg)
                        return None
                
                time.sleep(5)  # ç­‰å¾…5ç§’åé‡æ–°æ£€æŸ¥
                
            except Exception as e:
                error_msg = f"æ£€æŸ¥çŠ¶æ€å¼‚å¸¸: {str(e)}"
                print(f"âŒ {error_msg}")
                self.test_results["errors"].append(error_msg)
                time.sleep(5)
        
        error_msg = f"OCRå¤„ç†è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰"
        print(f"âŒ {error_msg}")
        self.test_results["errors"].append(error_msg)
        return None
    
    def run_analysis(self, task_id, k_pages=5):
        """
        è¿è¡ŒAIåˆ†æ
        
        Args:
            task_id (str): ä»»åŠ¡ID
            k_pages (int): æ¯Ké¡µåˆå¹¶ä¸ºä¸€ä¸ªåˆ†æå•å…ƒ
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        try:
            print(f"ğŸ¤– å¼€å§‹AIåˆ†æï¼ˆæ¯{k_pages}é¡µä¸ºä¸€ä¸ªå•å…ƒï¼‰...")
            
            data = {
                "task_id": task_id,
                "k_pages": k_pages
            }
            
            response = self.session.post(
                f"{self.base_url}/analyze",
                json=data,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ… AIåˆ†æå®Œæˆ")
                
                analysis_result = {
                    "k_pages": k_pages,
                    "chunks_count": result.get('chunks_count', 0),
                    "analysis_content": result.get('analysis_result', ''),
                    "word_document": result.get('word_document', None),
                    "timestamp": datetime.now().isoformat()
                }
                
                self.test_results["analysis_results"]["standard"] = analysis_result
                return analysis_result
                
            else:
                error_msg = f"AIåˆ†æå¤±è´¥: {response.status_code} - {response.text}"
                print(f"âŒ {error_msg}")
                self.test_results["errors"].append(error_msg)
                return None
                
        except Exception as e:
            error_msg = f"AIåˆ†æå¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            self.test_results["errors"].append(error_msg)
            return None
    
    def run_stream_analysis(self, task_id, k_pages=5):
        """
        è¿è¡Œæµå¼AIåˆ†æ
        
        Args:
            task_id (str): ä»»åŠ¡ID
            k_pages (int): æ¯Ké¡µåˆå¹¶ä¸ºä¸€ä¸ªåˆ†æå•å…ƒ
            
        Returns:
            dict: æµå¼åˆ†æç»“æœ
        """
        try:
            print(f"ğŸš€ å¼€å§‹æµå¼AIåˆ†æï¼ˆæ¯{k_pages}é¡µä¸ºä¸€ä¸ªå•å…ƒï¼‰...")
            
            data = {
                "task_id": task_id,
                "k_pages": k_pages
            }
            
            response = self.session.post(
                f"{self.base_url}/analyze_stream",
                json=data,
                headers={'Content-Type': 'application/json'},
                stream=True
            )
            
            if response.status_code == 200:
                stream_content = []
                chunks_count = 0
                word_document = None
                
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data: '):
                            try:
                                data_chunk = json.loads(line_str[6:])
                                
                                if data_chunk.get('type') == 'init':
                                    chunks_count = data_chunk.get('chunks_count', 0)
                                    print(f"ğŸ“Š æµå¼åˆ†æå¼€å§‹ï¼Œå…±{chunks_count}ä¸ªå†…å®¹å—")
                                    
                                elif data_chunk.get('type') == 'content':
                                    content = data_chunk.get('data', '')
                                    stream_content.append(content)
                                    print(".", end="", flush=True)
                                    
                                elif data_chunk.get('type') == 'word_generated':
                                    word_document = {
                                        'filename': data_chunk.get('filename'),
                                        'download_url': data_chunk.get('download_url')
                                    }
                                    print(f"\nğŸ“„ Wordæ–‡æ¡£å·²ç”Ÿæˆ: {word_document['filename']}")
                                    
                                elif data_chunk.get('type') == 'done':
                                    print("\nâœ… æµå¼åˆ†æå®Œæˆ")
                                    
                                elif data_chunk.get('type') == 'error':
                                    error_msg = f"æµå¼åˆ†æå¤±è´¥: {data_chunk.get('error')}"
                                    print(f"\nâŒ {error_msg}")
                                    self.test_results["errors"].append(error_msg)
                                    return None
                                    
                            except json.JSONDecodeError:
                                continue
                
                stream_result = {
                    "k_pages": k_pages,
                    "chunks_count": chunks_count,
                    "stream_content": ''.join(stream_content),
                    "word_document": word_document,
                    "timestamp": datetime.now().isoformat()
                }
                
                self.test_results["analysis_results"]["stream"] = stream_result
                return stream_result
                
            else:
                error_msg = f"æµå¼åˆ†æå¤±è´¥: {response.status_code} - {response.text}"
                print(f"âŒ {error_msg}")
                self.test_results["errors"].append(error_msg)
                return None
                
        except Exception as e:
            error_msg = f"æµå¼åˆ†æå¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            self.test_results["errors"].append(error_msg)
            return None
    
    def save_results(self, filename_prefix="auto_test"):
        """
        ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            filename_prefix (str): æ–‡ä»¶åå‰ç¼€
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ·»åŠ æµ‹è¯•æ€»ç»“
        self.test_results["test_info"]["end_time"] = datetime.now().isoformat()
        self.test_results["summary"] = {
            "total_pdfs": len(self.test_results["pdf_files"]),
            "ocr_success": len(self.test_results["ocr_results"]),
            "analysis_completed": len(self.test_results["analysis_results"]),
            "total_errors": len(self.test_results["errors"])
        }
        
        # ä¿å­˜JSONç»“æœ
        json_filename = f"{filename_prefix}_{timestamp}.json"
        json_path = os.path.join(self.output_dir, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {json_path}")
        
        # ä¿å­˜å¯è¯»çš„æ–‡æœ¬æŠ¥å‘Š
        txt_filename = f"{filename_prefix}_{timestamp}_report.txt"
        txt_path = os.path.join(self.output_dir, txt_filename)
        
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("è‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Š\n")
            f.write("="*80 + "\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            f.write("æµ‹è¯•ä¿¡æ¯:\n")
            f.write(f"  å¼€å§‹æ—¶é—´: {self.test_results['test_info']['start_time']}\n")
            f.write(f"  ç»“æŸæ—¶é—´: {self.test_results['test_info']['end_time']}\n")
            f.write(f"  æœåŠ¡å™¨åœ°å€: {self.test_results['test_info']['base_url']}\n")
            f.write(f"  ç»“æœç›®å½•: {self.test_results['test_info']['output_dir']}\n\n")
            
            # æµ‹è¯•æ€»ç»“
            summary = self.test_results["summary"]
            f.write("æµ‹è¯•æ€»ç»“:\n")
            f.write(f"  PDFæ–‡ä»¶æ€»æ•°: {summary['total_pdfs']}\n")
            f.write(f"  OCRæˆåŠŸæ•°é‡: {summary['ocr_success']}\n")
            f.write(f"  åˆ†æå®Œæˆæ•°é‡: {summary['analysis_completed']}\n")
            f.write(f"  é”™è¯¯æ€»æ•°: {summary['total_errors']}\n\n")
            
            # PDFæ–‡ä»¶åˆ—è¡¨
            f.write("å¤„ç†çš„PDFæ–‡ä»¶:\n")
            for pdf_file in self.test_results["pdf_files"]:
                f.write(f"  - {pdf_file}\n")
            f.write("\n")
            
            # OCRç»“æœ
            if self.test_results["ocr_results"]:
                f.write("OCRè¯†åˆ«ç»“æœ:\n")
                for result in self.test_results["ocr_results"]:
                    f.write(f"  æ–‡ä»¶: {result.get('filename', 'Unknown')}\n")
                    if 'error' in result:
                        f.write(f"    é”™è¯¯: {result['error']}\n")
                    else:
                        pages = result.get('pages', [])
                        f.write(f"    è¯†åˆ«é¡µæ•°: {len(pages)}\n")
                        f.write(f"    æ—¶é—´æˆ³: {result.get('timestamp', 'Unknown')}\n")
                f.write("\n")
            
            # åˆ†æç»“æœ
            if self.test_results["analysis_results"]:
                f.write("AIåˆ†æç»“æœ:\n")
                
                # æ ‡å‡†åˆ†æ
                if "standard" in self.test_results["analysis_results"]:
                    std_result = self.test_results["analysis_results"]["standard"]
                    f.write("  æ ‡å‡†åˆ†æ:\n")
                    f.write(f"    åˆ†æå•å…ƒ: æ¯{std_result['k_pages']}é¡µ\n")
                    f.write(f"    å†…å®¹å—æ•°: {std_result['chunks_count']}\n")
                    f.write(f"    åˆ†ææ—¶é—´: {std_result['timestamp']}\n")
                    if std_result.get('word_document'):
                        f.write(f"    Wordæ–‡æ¡£: {std_result['word_document']['filename']}\n")
                    f.write("\n")
                
                # æµå¼åˆ†æ
                if "stream" in self.test_results["analysis_results"]:
                    stream_result = self.test_results["analysis_results"]["stream"]
                    f.write("  æµå¼åˆ†æ:\n")
                    f.write(f"    åˆ†æå•å…ƒ: æ¯{stream_result['k_pages']}é¡µ\n")
                    f.write(f"    å†…å®¹å—æ•°: {stream_result['chunks_count']}\n")
                    f.write(f"    åˆ†ææ—¶é—´: {stream_result['timestamp']}\n")
                    if stream_result.get('word_document'):
                        f.write(f"    Wordæ–‡æ¡£: {stream_result['word_document']['filename']}\n")
                    f.write("\n")
            
            # é”™è¯¯ä¿¡æ¯
            if self.test_results["errors"]:
                f.write("é”™è¯¯è®°å½•:\n")
                for i, error in enumerate(self.test_results["errors"], 1):
                    f.write(f"  {i}. {error}\n")
                f.write("\n")
            
            # åˆ†æå†…å®¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if self.test_results["analysis_results"]:
                f.write("\n" + "="*80 + "\n")
                f.write("è¯¦ç»†åˆ†æå†…å®¹\n")
                f.write("="*80 + "\n\n")
                
                if "standard" in self.test_results["analysis_results"]:
                    f.write("æ ‡å‡†åˆ†æå†…å®¹:\n")
                    f.write("-"*60 + "\n")
                    f.write(self.test_results["analysis_results"]["standard"]["analysis_content"])
                    f.write("\n\n")
                
                if "stream" in self.test_results["analysis_results"]:
                    f.write("æµå¼åˆ†æå†…å®¹:\n")
                    f.write("-"*60 + "\n")
                    f.write(self.test_results["analysis_results"]["stream"]["stream_content"])
                    f.write("\n\n")
        
        print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {txt_path}")
        
        return json_path, txt_path
    
    def run_full_test(self, pdf_path, k_pages=5):
        """
        è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            k_pages (int): æ¯Ké¡µåˆå¹¶ä¸ºä¸€ä¸ªåˆ†æå•å…ƒ
            
        Returns:
            bool: æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–æµ‹è¯•...")
        print(f"ğŸ“‚ PDFè·¯å¾„: {pdf_path}")
        print(f"ğŸ“Š åˆ†æå•å…ƒ: æ¯{k_pages}é¡µ")
        print("-" * 80)
        
        # 1. æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
        if not self.check_server_status():
            return False
        
        # 2. æŸ¥æ‰¾PDFæ–‡ä»¶
        pdf_files = self.find_pdf_files(pdf_path)
        if not pdf_files:
            print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
            return False
        
        # 3. ä¸Šä¼ PDFæ–‡ä»¶
        task_id = self.upload_pdf_files(pdf_files)
        if not task_id:
            return False
        
        # 4. ç­‰å¾…OCRå®Œæˆ
        ocr_results = self.wait_for_ocr_completion(task_id)
        if not ocr_results:
            return False
        
        # 5. è¿è¡ŒAIåˆ†æ
        analysis_success = False
        
        # # æ ‡å‡†åˆ†æ
        # print("\n" + "="*50)
        # analysis_result = self.run_analysis(task_id, k_pages)
        # if analysis_result:
        #     analysis_success = True
        
        print("\n" + "="*50)
        stream_result = self.run_stream_analysis(task_id, k_pages)
        if stream_result:
            analysis_success = True
        
        # 6. ä¿å­˜ç»“æœ
        print("\n" + "="*50)
        json_path, txt_path = self.save_results()
        
        # è¾“å‡ºæœ€ç»ˆæ€»ç»“
        print("\n" + "="*80)
        print("ğŸ‰ è‡ªåŠ¨åŒ–æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“‹ å¤„ç†PDF: {len(pdf_files)} ä¸ª")
        print(f"âœ… OCRæˆåŠŸ: {len(ocr_results)} ä¸ª")
        print(f"ğŸ¤– åˆ†æå®Œæˆ: {len(self.test_results['analysis_results'])} ä¸ª")
        print(f"âŒ é”™è¯¯æ•°é‡: {len(self.test_results['errors'])} ä¸ª")
        print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {json_path}")
        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Š: {txt_path}")
        
        return analysis_success


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PDFè‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·')
    parser.add_argument('--pdf_path', default = "data/æ¡£æ¡ˆ3/æ¸©å·é…¯æºåŒ–å·¥æœ‰é™å…¬å¸", help='PDFæ–‡ä»¶è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼‰')
    parser.add_argument('--url', default='http://localhost:5500', help='Webåº”ç”¨URLï¼ˆé»˜è®¤: http://localhost:5000ï¼‰')
    parser.add_argument('--output', default='test_results', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: test_resultsï¼‰')
    parser.add_argument('--k-pages', type=int, default=10, help='æ¯Ké¡µåˆå¹¶ä¸ºä¸€ä¸ªåˆ†æå•å…ƒï¼ˆé»˜è®¤: 5ï¼‰')
    
    args = parser.parse_args()
    # æ£€æŸ¥PDFè·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.pdf_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {args.pdf_path}")
        sys.exit(1)
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = AutoTestRunner(base_url=args.url, output_dir=args.output)
    
    # è¿è¡Œæµ‹è¯•
    success = runner.run_full_test(
        pdf_path=args.pdf_path,
        k_pages=args.k_pages,
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
